#!/usr/bin/env python

from statstools.parallel import run_pool
from statstools.significance import SignificanceWorker
import os


if __name__ == '__main__':
    from rootpy.extern.argparse import ArgumentParser

    parser = ArgumentParser()
    parser.add_argument('--jobs', type=int, default=-1)
    parser.add_argument('--name', default='combined')
    parser.add_argument('--overwrite', action='store_true', default=False)
    parser.add_argument('--unblind', action='store_true', default=False)
    parser.add_argument('--profile', default=None)
    parser.add_argument('files', nargs='+')
    args = parser.parse_args()

    # find all root files
    root_files = []
    for file in args.files:
        if os.path.isdir(file):
            # walk below this path
            for dirpath, dirnames, filenames in os.walk(file):
                for filename in filenames:
                    if filename.endswith('.root'):
                        root_files.append(os.path.join(dirpath, filename))
        else:
            root_files.append(file)

    # define the workers
    workers = [SignificanceWorker(file, args.name,
                                  observed=args.unblind,
                                  profile=args.profile,
                                  overwrite=args.overwrite)
               for file in root_files]

    # run the pool
    run_pool(workers, n_jobs=args.jobs)
